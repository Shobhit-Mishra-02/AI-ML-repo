{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bc0f19b",
   "metadata": {},
   "source": [
    "# Imbalace in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2abdaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4d5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38de9f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b32dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"RowNumber\",\"CustomerId\", \"Surname\",\"Geography\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab56f89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Gender           10000 non-null  object \n",
      " 2   Age              10000 non-null  int64  \n",
      " 3   Tenure           10000 non-null  int64  \n",
      " 4   Balance          10000 non-null  float64\n",
      " 5   NumOfProducts    10000 non-null  int64  \n",
      " 6   HasCrCard        10000 non-null  int64  \n",
      " 7   IsActiveMember   10000 non-null  int64  \n",
      " 8   EstimatedSalary  10000 non-null  float64\n",
      " 9   Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(1)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb936e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data, drop_first=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561c4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Exited\"], axis=1)\n",
    "Y = df.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa41bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After removing some useless fields and applying removing categorical features, we get this..\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1d982",
   "metadata": {},
   "source": [
    "But, If you notice very carefully then you will get to know that we have got about 7 thousand data points and about 2 thousand data points from 1, so this is known as imbalance in dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a459101a",
   "metadata": {},
   "source": [
    "### 1. Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69cbe8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_0_count = Y.value_counts()[0]\n",
    "target_1_count = Y.value_counts()[1]\n",
    "\n",
    "df_with_0 = df[df.Exited == 0]\n",
    "df_with_1 = df[df.Exited == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1891c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersampling =  pd.concat([df_with_0.sample(target_1_count), df_with_1], axis=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc25a7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2037\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_undersampling.Exited.value_counts() # chekout the balance in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ef43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_undersample, X_test_undersample, Y_train_undersample, Y_test_undersample = train_test_split(df_undersampling.drop([\"Exited\"], axis=1), df_undersampling.Exited, random_state=1, stratify=df_undersampling.Exited, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d1b6391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3259, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_undersample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1eb394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3259,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_undersample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e048be3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1630\n",
       "1    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_undersample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ecad56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 481.6071 - accuracy: 0.4732\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 7.9919 - accuracy: 0.4913\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 4.0577 - accuracy: 0.4854\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 4.2909 - accuracy: 0.5081\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 2.6673 - accuracy: 0.4962\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 3.4807 - accuracy: 0.5035\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 2.3192 - accuracy: 0.4903\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 3.4632 - accuracy: 0.4959\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 2.2112 - accuracy: 0.4940\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 3.6005 - accuracy: 0.5051\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 3.1644 - accuracy: 0.5023\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.6744 - accuracy: 0.5118\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 2.1123 - accuracy: 0.5008\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 4.9816 - accuracy: 0.5020\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 2.9490 - accuracy: 0.5118\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 2.9579 - accuracy: 0.4900\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 2.9132 - accuracy: 0.5140\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 4.4705 - accuracy: 0.5002\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 3.0442 - accuracy: 0.4827\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 2.4831 - accuracy: 0.5023\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 2.7389 - accuracy: 0.5081\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.9884 - accuracy: 0.5170\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.8646 - accuracy: 0.5100\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.8705 - accuracy: 0.5075\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 3.2993 - accuracy: 0.4943\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 4.4739 - accuracy: 0.4974\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.9145 - accuracy: 0.5017\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0675 - accuracy: 0.5183\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.5278 - accuracy: 0.4913\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.3471 - accuracy: 0.5069\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.2964 - accuracy: 0.4836\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.4351 - accuracy: 0.5143\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.2687 - accuracy: 0.5189\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.7305 - accuracy: 0.4952\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.2627 - accuracy: 0.5146\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1702 - accuracy: 0.5216\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.3170 - accuracy: 0.5143\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.2626 - accuracy: 0.4952\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.7322 - accuracy: 0.5164\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.1724 - accuracy: 0.5044\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0480 - accuracy: 0.5158\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.3565 - accuracy: 0.5075\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0025 - accuracy: 0.5213\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9317 - accuracy: 0.5222\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8953 - accuracy: 0.5327\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.2278 - accuracy: 0.5146\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.0462 - accuracy: 0.5124\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8734 - accuracy: 0.5164\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9245 - accuracy: 0.5057\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 1.2788 - accuracy: 0.5106\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9435 - accuracy: 0.5054\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8793 - accuracy: 0.5241\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7553 - accuracy: 0.5238\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.9295 - accuracy: 0.5158\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8965 - accuracy: 0.5140\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.5133\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7784 - accuracy: 0.5195\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.5318\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7621 - accuracy: 0.5284\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.8024 - accuracy: 0.5284\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7903 - accuracy: 0.5204\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7432 - accuracy: 0.5354\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7764 - accuracy: 0.5097\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7375 - accuracy: 0.5339\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7159 - accuracy: 0.5400\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.5385\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.5293\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7015 - accuracy: 0.5238\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7114 - accuracy: 0.5232\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.5400\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.5284\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5354\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.5379\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5379\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.5379\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5407\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5440\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5345\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5446\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5379\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5345\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5367\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5419\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5437\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5450\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5502\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5465\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5391\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5496\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6879 - accuracy: 0.5502\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5523\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5480\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5450\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5523\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5468\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5425\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5440\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6885 - accuracy: 0.5422\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5364\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d0ea93ee0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_underSmp = keras.Sequential([\n",
    "    keras.layers.Dense(6, input_shape=(9,), activation=\"relu\"),\n",
    "    keras.layers.Dense(3, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_underSmp.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_underSmp.fit(X_train_undersample, Y_train_undersample, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a719a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b18fa15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "underSmp_prediction = model_underSmp.predict(X_test_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d623c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRoundOutput(arr):\n",
    "    lt = []\n",
    "    for i in arr.reshape(-1,):\n",
    "        lt.append(np.round(i))\n",
    "        \n",
    "    return lt\n",
    "\n",
    "lt_underSmp = getRoundOutput(underSmp_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07e13589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.53      0.58       481\n",
      "         1.0       0.45      0.55      0.50       334\n",
      "\n",
      "    accuracy                           0.54       815\n",
      "   macro avg       0.54      0.54      0.54       815\n",
      "weighted avg       0.56      0.54      0.54       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lt_underSmp, Y_test_undersample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd385df",
   "metadata": {},
   "source": [
    "## 2. Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0941c461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_0_count,target_1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec9b9bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4912</th>\n",
       "      <td>748</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>152335.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126743.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>662</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>104568.41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8059.44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953</th>\n",
       "      <td>711</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>177626.77</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16392.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9602</th>\n",
       "      <td>634</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>95727.05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97939.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>714</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>99141.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72496.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>685</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>94238.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50664.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>604</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>144453.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>190998.96</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9220</th>\n",
       "      <td>598</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197727.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>589</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>119961.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65156.83</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>608</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>114203.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77830.36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7963 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "4912          748   60       0  152335.70              1          1   \n",
       "3898          662   59       2  104568.41              1          1   \n",
       "8953          711   42       3  177626.77              3          0   \n",
       "9602          634   59       3   95727.05              1          0   \n",
       "4287          714   53       1   99141.86              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "3917          685   50       6   94238.75              2          1   \n",
       "1951          604   53       8  144453.75              1          1   \n",
       "9220          598   60       4       0.00              1          1   \n",
       "2347          589   55       7  119961.48              1          1   \n",
       "1367          608   44       7  114203.47              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Gender_Male  \n",
       "4912               0        126743.33       1            1  \n",
       "3898               0          8059.44       1            1  \n",
       "8953               1         16392.72       1            1  \n",
       "9602               0         97939.40       1            0  \n",
       "4287               1         72496.05       1            1  \n",
       "...              ...              ...     ...          ...  \n",
       "3917               1         50664.07       1            0  \n",
       "1951               0        190998.96       1            1  \n",
       "9220               0        197727.14       1            1  \n",
       "2347               0         65156.83       1            1  \n",
       "1367               1         77830.36       1            1  \n",
       "\n",
       "[7963 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_1.sample(target_0_count, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "361d792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ovrSmp = pd.concat([df_with_1.sample(target_0_count, replace=True), df_with_0], axis=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa81cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ovrSmp, X_test_ovrSmp, Y_train_ovrSmp, Y_test_ovrSmp = train_test_split(df_ovrSmp.drop([\"Exited\"], axis=1), df_ovrSmp.Exited, random_state=1, stratify=df_ovrSmp.Exited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e01b5bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11944, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ovrSmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85396dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11944,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_ovrSmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "857ea38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 1372.3658 - accuracy: 0.5411\n",
      "Epoch 2/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 5.4224 - accuracy: 0.5115\n",
      "Epoch 3/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 5.0374 - accuracy: 0.5121\n",
      "Epoch 4/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 5.0584 - accuracy: 0.5188\n",
      "Epoch 5/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 4.1454 - accuracy: 0.5087\n",
      "Epoch 6/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 4.9115 - accuracy: 0.5080\n",
      "Epoch 7/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 4.7143 - accuracy: 0.5020\n",
      "Epoch 8/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 4.4614 - accuracy: 0.5117\n",
      "Epoch 9/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 3.6223 - accuracy: 0.5025\n",
      "Epoch 10/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 3.8073 - accuracy: 0.5190\n",
      "Epoch 11/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 3.5814 - accuracy: 0.5222\n",
      "Epoch 12/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 3.2314 - accuracy: 0.5285\n",
      "Epoch 13/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 2.4585 - accuracy: 0.5318\n",
      "Epoch 14/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 2.3498 - accuracy: 0.5299\n",
      "Epoch 15/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 1.9615 - accuracy: 0.5279\n",
      "Epoch 16/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 1.7432 - accuracy: 0.5366\n",
      "Epoch 17/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 1.5781 - accuracy: 0.5352\n",
      "Epoch 18/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 1.5218 - accuracy: 0.5293\n",
      "Epoch 19/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 1.1761 - accuracy: 0.5366\n",
      "Epoch 20/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 1.2193 - accuracy: 0.5392\n",
      "Epoch 21/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.8813 - accuracy: 0.5399\n",
      "Epoch 22/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.8372 - accuracy: 0.5383\n",
      "Epoch 23/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.7791 - accuracy: 0.5399\n",
      "Epoch 24/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.7349 - accuracy: 0.5462\n",
      "Epoch 25/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.7056 - accuracy: 0.5446\n",
      "Epoch 26/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5496\n",
      "Epoch 27/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5566\n",
      "Epoch 28/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6875 - accuracy: 0.5595\n",
      "Epoch 29/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6876 - accuracy: 0.5580\n",
      "Epoch 30/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6870 - accuracy: 0.5590\n",
      "Epoch 31/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6864 - accuracy: 0.5591\n",
      "Epoch 32/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5666\n",
      "Epoch 33/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5581\n",
      "Epoch 34/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5267\n",
      "Epoch 35/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5306\n",
      "Epoch 36/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5241\n",
      "Epoch 37/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5152\n",
      "Epoch 38/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5038\n",
      "Epoch 39/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5128\n",
      "Epoch 40/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.5145\n",
      "Epoch 41/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6917 - accuracy: 0.5111\n",
      "Epoch 42/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5235\n",
      "Epoch 43/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5150\n",
      "Epoch 44/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5095\n",
      "Epoch 45/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5043\n",
      "Epoch 46/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5071\n",
      "Epoch 47/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6918 - accuracy: 0.5074\n",
      "Epoch 48/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5106\n",
      "Epoch 49/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6922 - accuracy: 0.5076\n",
      "Epoch 50/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5054\n",
      "Epoch 51/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6914 - accuracy: 0.5054\n",
      "Epoch 52/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.5038\n",
      "Epoch 53/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5065\n",
      "Epoch 54/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5033\n",
      "Epoch 55/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6923 - accuracy: 0.5013\n",
      "Epoch 56/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6921 - accuracy: 0.5080\n",
      "Epoch 57/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6954 - accuracy: 0.5018\n",
      "Epoch 58/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4936\n",
      "Epoch 59/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5004\n",
      "Epoch 60/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5020\n",
      "Epoch 61/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5003\n",
      "Epoch 62/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.4970\n",
      "Epoch 63/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4953\n",
      "Epoch 64/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.4977\n",
      "Epoch 65/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.4966\n",
      "Epoch 66/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5019\n",
      "Epoch 67/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5046\n",
      "Epoch 68/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4997\n",
      "Epoch 69/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4921\n",
      "Epoch 70/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.4952\n",
      "Epoch 71/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.4949\n",
      "Epoch 72/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4939\n",
      "Epoch 73/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5077\n",
      "Epoch 74/100\n",
      "374/374 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4960\n",
      "Epoch 75/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5005\n",
      "Epoch 76/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.4996\n",
      "Epoch 77/100\n",
      "374/374 [==============================] - 1s 1ms/step - loss: 0.6928 - accuracy: 0.4951\n",
      "Epoch 78/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.4992\n",
      "Epoch 79/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.5038\n",
      "Epoch 80/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.5003\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.5033\n",
      "Epoch 82/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4981\n",
      "Epoch 83/100\n",
      "374/374 [==============================] - 1s 1ms/step - loss: 0.6928 - accuracy: 0.4991\n",
      "Epoch 84/100\n",
      "374/374 [==============================] - 1s 1ms/step - loss: 0.6927 - accuracy: 0.5024\n",
      "Epoch 85/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4997\n",
      "Epoch 86/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4952\n",
      "Epoch 87/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.5023\n",
      "Epoch 88/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.4972\n",
      "Epoch 89/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.4999\n",
      "Epoch 90/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.5010\n",
      "Epoch 91/100\n",
      "374/374 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4931\n",
      "Epoch 92/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4958\n",
      "Epoch 93/100\n",
      "374/374 [==============================] - 1s 1ms/step - loss: 0.6927 - accuracy: 0.5008\n",
      "Epoch 94/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4970\n",
      "Epoch 95/100\n",
      "374/374 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4959\n",
      "Epoch 96/100\n",
      "374/374 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.4983\n",
      "Epoch 97/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6929 - accuracy: 0.4936\n",
      "Epoch 98/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6928 - accuracy: 0.4977\n",
      "Epoch 99/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.4985\n",
      "Epoch 100/100\n",
      "374/374 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d0fd55100>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ovrSmp = keras.Sequential([\n",
    "    keras.layers.Dense(6, input_shape=(9,), activation=\"relu\"),\n",
    "    keras.layers.Dense(3, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_ovrSmp.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_ovrSmp.fit(X_train_ovrSmp, Y_train_ovrSmp, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49052314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "ovrSmp_prediction = model_underSmp.predict(X_test_ovrSmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9059120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_ovrSmp = getRoundOutput(ovrSmp_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f021f1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.55      0.60      2420\n",
      "         1.0       0.45      0.57      0.50      1562\n",
      "\n",
      "    accuracy                           0.56      3982\n",
      "   macro avg       0.56      0.56      0.55      3982\n",
      "weighted avg       0.58      0.56      0.56      3982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lt_ovrSmp, Y_test_ovrSmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18748504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
